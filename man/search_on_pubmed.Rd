% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/search_on_pubmed.R
\name{search_on_pubmed}
\alias{search_on_pubmed}
\title{Perform a search on PubMed}
\usage{
search_on_pubmed(
  search_string,
  batch_size = 25,
  max_to_get = 25,
  api_key = NULL
)
}
\arguments{
\item{search_string}{(character vector of length 1) that is used for
querying PubMed (standard PubMed syntax, see reference for
details).}

\item{batch_size}{Integer (>= 1): size of the batch of PubMed records
to be retrieved at one time.}

\item{max_to_get}{Integer (>= 1): maximum number of records to
retrieve. Note that, if they are not finished, a complete batch
will be always retrieved; hence, more than \code{max_to_get} records
will be retrieved Set it to \code{Inf} to be sure to retrieve all
the possible results.}

\item{api_key}{(character vector of length 1): user-specific API key
to increase the limit of queries per second above three. You can
obtain your key from NCBI (see
\url{https://ncbiinsights.ncbi.nlm.nih.gov/2017/11/02/new-api-keys-for-the-e-utilities/}}
}
\value{
An object of class
\code{\link[revtools]{bibliography-class}}.
}
\description{
This function wraps
\code{easyPubMed::\link[easyPubMed]{get_pubmed_ids}} and
\code{easyPubMed::\link[easyPubMed]{fetch_pubmed_data}} to collect
results of a query to
\href{https://www.ncbi.nlm.nih.gov/pubmed/}{PubMed}
}
\examples{
\dontrun{
    # This retrieve a (short) set of results (batch size auto-resize
    # itself).
    search_on_pubmed("(machine learning) AND lanera[Author]")

    # More reults but retreivet just a few
    search_on_pubmed("machine learning", max_to_get = 200)

    # -> ATTENTION <- big ammount of reults here: 36296! (2019-12-22)
    search_on_pubmed("machine learning",
        batch_size = 5000,       # this is the maximum for Scopus API
        max_to_get = Inf
    )
}
}
\references{
\url{https://www.ncbi.nlm.nih.gov/books/NBK3827/#_pubmedhelp_Search_Field_Descriptions_and_}
}
